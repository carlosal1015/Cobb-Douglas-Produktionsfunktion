$\py{2 + 4**2}$ % Imprime el valor.

\py{'ABC'.lower()} % Imprime el valor.

\pyc{var = 2}$\py{var}$ % Calcula el valor, pero no imprime

\pyb{x = 5}\py{x} % Imprime el programa y calcula.

\pyv{y = 0} % % Imprime el programa, pero no calcula.\py{y}

\pys{\verb|z = !{x}|} % Reemplaza el valor del objeto que va entre llaves.

\begin{pycode}
print(r'\begin{center}')
print(r'\textit{A message from Python!}')
print(r'\end{center}')
\end{pycode}

\begin{pyconsole}
x_1 = 1 + 1
x_1
\end{pyconsole}


\begin{pylabcode}[plotsession]
import csv
from statistics import mean, variance
import math
import matplotlib.patches as mpatches
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
rc('text', usetex=True)
rc('font', **{'family':'serif', 'serif':['Times']})
rc('legend', fontsize=10.0)
def plotCD(fig, data, reg1, reg2, log):
	"""
	Método responsable de hacer el trazado de las superficies de regresión.
	Se recomienda establecer el divisor del intervalo con la correspondencia con los datos iniciales.
	"""
	interval = (max(data["K"]) - min(data["K"])) // 20 
	interval2 = (max(data["L"]) - min(data["L"])) // 20
	
	x = np.arange(min(data["K"]), max(data["K"]), interval)
	y = np.arange(min(data["L"]), max(data["L"]), interval2)
	x, y = np.meshgrid(x, y)
	
	fig.suptitle('Cobb-Douglas Production Function')
	z1 = (math.exp(reg1[0]) if not log else reg1[0]) * x ** reg1[1] * y ** (1 - reg1[1])
	z2 = (math.exp(reg2[0]) if not log else reg2[0]) * x ** reg2[1] * y ** reg2[2]
	z = [z1, z2]

	for i in range (2):
		ax = fig.add_subplot(1, 2, i + 1, projection = '3d')
		ax.plot_wireframe(x, y, z[i], antialiased = False, rstride = 2, cstride = 2, color = "orange" if i==0 else "blue", linewidth = 1)
		ax.set_title("Constant returns to scale" if i == 0 else "Variable returns to scale", fontweight="bold")
		ax.set_xlabel('K', fontweight="bold")
		ax.set_ylabel('L', fontweight="bold")
		ax.set_zlabel('Y', fontweight="bold")
		handles, labels = ax.get_legend_handles_labels()
		ax.legend(handles, labels)
		red_patch = mpatches.Patch(color='red', label='Initial data points')
		plot_patch = mpatches.Patch(color="orange" if i == 0 else "blue", label="Regression surface")
		legend(handles = [red_patch, plot_patch])
		ax.scatter(data["K"], data["L"], data["Y"], c = "red", linewidth = 0, antialiased = False)
	savefig('plot2.pdf', bbox_inches='tight')

def getData(file, log, d = ';'):
	data = {"Y": [],
		"K": [],
		"L": [],
		"P": []}

	with open(file, 'r', newline = '') as csvfile:
		freader = csv.reader(csvfile, delimiter = d)
		next(freader)
		for row in freader:
			if (not log):
				row = [np.log(np.float(n.replace(",", "."))) for n in row]
			else:
				row = [float(n.replace(",", ".")) for n in row]
			data["Y"].append(row[0])
			data["K"].append(row[1])
			data["L"].append(row[2])
			if (len(row) > 3): data["P"].append(row[3])
		return data

class RegressionModel:
	y = 0
	x1 = []
	x2 = None
	x3 = None
	residuals = []
	file = ""
	log = False
	model = []
	cond = 0


	def __init__(self, y, x1, x2 = None, x3 = None):
		self.y = y
		self.x1 = x1
		self.x2 = x2
		self.x3 = x3

	def cov(self, a, b): #Method for calculating the covariance
		cov = 0.0
		for i in range(len(a)):
			cov += (a[i] - mean(a)) * (b[i] - mean(b))
		return cov / (len(a) - 1)

def se(self, y, x1, residuals, x2 = None, x3 = None): # Errores estándar
	se = []
	SSr = sum([(res) ** 2 for res in residuals])
	MSE = SSr / (len(y) - 3)
	if (x2 is None):
		s = (sum([res ** 2 for res in residuals]) / (len(y) - 2)) ** 0.5
		SSX = sum([(x - mean(x1)) ** 2 for x in x1])
		xsq = [x ** 2 for x in x1]
		se.append(s * (sum(xsq) / (len(y) * SSX)) ** 0.5)
		se.append(s / (SSX) ** 0.5)
		return se
	elif (x3 is None):
		mat = np.column_stack((np.array(np.ones(len(y))), np.array(x1), np.array(x2)))
	else:
		mat = np.column_stack((np.array(np.ones(len(y))), np.array(x1), np.array(x2), np.array(x3)))
	mat = np.linalg.pinv(np.matmul(mat.transpose(), mat))
	se = [(d * MSE) ** 0.5 for d in mat.diagonal()]
	return se

	def getRes(self, y, x1, b0, b1, x2 = None, b2 = None, x3 = None, b3 = None): # Obtener los residuos de la regresión calculada.
	
		res = []
		yp = []
		if (x2 is None):
			for i in range(len(y)):
				yp.append(b0 + b1 * x1[i])
				res.append(y[i] - yp[i])
		elif (x3 is None):
			for i in range(len(y)):
				yp.append(b0 + b1 * x1[i] + b2 * x2[i])
				res.append(y[i] - yp[i])
		else:
			for i in range(len(y)):
				yp.append(b0 + b1 * x1[i] + b2 * x2[i] + b3 * x3[i])
				res.append(y[i] - yp[i])
		return res, yp

	def r2(self, y, residuals, ym): # Coeficiente de determinación
		SSr = sum([res ** 2 for res in residuals])
		SSt = sum([(yi - ym) ** 2 for yi in y])
		return 1 - (SSr / SSt) if SSt !=0 else 1

	def r2_adj(self, y, R2, fac): # Coeficiente de determinación (ajustado)
		return 1 - (1 - R2) * ((len(y) - 1) / (len(y) - fac - 1))

def f(self, y, yp, R2, fac): # Prueba F
	SSE = 0.0
	SSM = 0.0
	for i in range(len(y)):
		SSE += (y[i] - yp[i]) ** 2
		SSM += (yp[i] - mean(y)) ** 2
	return (SSM / (fac)) / (SSE / (len(y) - fac - 1)) if SSE != 0 else math.inf

	def t(self, coeff, se): # Estatístico F
		t_stat = []
		for i in range(len(coeff)):
			if se[i] ==0:
				continue
			t_stat.append(coeff[i] / se[i])
		return t_stat

	def dw(self, residuals): # Criterios de Durbin-Watson
		sumr = 0.0
		rsq = sum([res ** 2 for res in residuals])
		for i in range(1, len(residuals)):
			sumr += (residuals[i] - residuals[i - 1]) ** 2
		return sumr / rsq if rsq !=0 else 0

	def jb(self, y, residuals): # Prueba de Jarque-Bera
		m3 = sum([res ** 3 for res in residuals]) / len(y)
		sig3 = (sum([res ** 2 for res in residuals]) / len(y)) ** 1.5
		m4 = sum([res ** 4 for res in residuals]) / len(y)
		sig4 = (sum([res ** 2 for res in residuals]) / len(y)) ** 2
		S = m3 / sig3 if sig3 !=0 else 0
		C = m4 / sig4 if sig3 !=0 else 0
		jb_stat = len(y) * ((S ** 2) / 6 + ((C - 3) ** 2) / 24)
		return jb_stat

	def regr(self, y, x1, x2=None, x3=None): # Método para calcular los coeficientes de regresión.
		if x2 is None:
			b1 = self.cov(x1, y) / variance(x1)
			b0 = mean(y) - b1 * mean(x1)
			coeff = [b0, b1]
			return coeff
		elif x3 is None:
			X = np.column_stack((np.array(np.ones(len(y))), np.array(x1), np.array(x2)))
		else:
			X = np.column_stack((np.array(np.ones(len(y))), np.array(x1), np.array(x2), np.array(x3)))
		Y = np.column_stack(np.array(y))
		A = np.linalg.inv(np.matmul(X.transpose(), X))
		B = np.matmul(X.transpose(), Y.transpose())
		coeff = np.matmul(A, B)
		self.cond = np.linalg.cond(np.matmul(X.transpose(), X))
		coeff = np.squeeze(np.asarray(coeff))
		return coeff

	def CD(self): # Método principal para el cálculo de regresión y estadísticas.
		y = self.y
		x1 =self.x1
		x2 = self.x2
		x3 = self.x3
		model = self.regr(y, x1, x2, x3)
		if len(model) == 3:
			res, yp = self.getRes(y, x1, model[0], model[1], x2, model[2])
		elif len(model) == 2:
			res, yp = self.getRes(y, x1, model[0], model[1])
		else:
			res, yp = self.getRes(y, x1, model[0], model[1], x2, model[2], x3, model[3])
	
		R2 = self.r2(y, res, mean(y))
		R2_adj = self.r2_adj(y, R2, len(model) - 1)
		dw_test = self.dw(res)
		F = self.f(y, yp, R2, len(model) - 1)
		SE = self.se(y, x1, res, x2, x3)
		t_stat = self.t(model, SE)
		jb_test = self.jb(y, res)
		self.model = model
		res = {"Regression coefficients": model,
			"Standard errors": SE,
			"t-statistic": t_stat,
			"Coefficient of determination": R2,
			"Coefficient of determination (adjusted)": R2_adj,
			"F-test": F,
			"Durbin-Watson statistic": dw_test,
			"Jarque-Bera test": jb_test,
			"Condition number for X^tX": self.cond}
	
		names_stat = ["Regression coefficients", "Standard errors", "t-statistic", "Coefficient of determination", "Coefficient of determination (adjusted)"
		, "F-test", "Durbin-Watson statistic", "Jarque-Bera test","Condition number for X^tX"]
		print("{0}\n{1:^103}\n{2}".format("=" * 103, "Regression summary", "=" * 103))
		for i in range(len(names_stat)):
			print("{0:40} {1:}".format(names_stat[i], res[names_stat[i]]))
		print("\n")
		return res

def model(): # Interfaz CLI
	while(True):
		try:
			file = input("Especifique el nombre del archivo de datos: ")
			ans = input("¿Aplicar logaritmo natural? (0-SÍ, 1-NO): ")
			while (ans not in ("1", "0")):
				print("Ingrese 0 para SÍ y 1 para NO!\n")
				ans = input("¿Aplicar logaritmo natural? (0-SÍ, 1-NO): ")
			log = ans == "1"
			data = getData(file, log)
			fig = plt.figure()
			if (len(data["P"]) !=0):
				reg3 = RegressionModel([a - b for a, b in zip(data["Y"], data["P"])],
				[a - b for a, b in zip(data["K"], data["P"])],
				[a - b for a, b in zip(data["L"], data["P"])])
				reg4 = RegressionModel(data["Y"], data["K"], data["L"], data["P"])
				reg3.CD()
				reg4.CD()
			else:
				reg1 = RegressionModel([a - b for a, b in zip(data["Y"], data["L"])],
				[a - b for a, b in zip(data["K"], data["L"])])
				reg2 = RegressionModel(data["Y"], data["K"], data["L"])
				reg1.CD()
				reg2.CD()
				plotCD(fig, getData(file, True), reg1.model, reg2.model, log)
		except Exception as err:
			print(err,"\n")
			continue
\end{pylabcode}

%\begin{pythontexcustomcode}{py}
%from sympy import *
%import numpy as np
%from matplotlib.pylab import plt
%#%matplotlib inline
%init_printing(use_latex=True)
%
%# Register symbols
%var("L K Y A a")
%
%# Cobb-Douglas production function:
%Y =  A*(L**a)*K**(1-a)
%
%# Assign number to A and a:
%Ys = Y.subs({A:10, a:0.6})
%
%# Plot 3D chart in which K and L are changed 0 to 10
%plotting.plot3d(Ys, (K, 0, 10), (L, 0, 10))
%
%# Turn sympy symbols into python function:
%Ys_func = lambdify((K, L), Ys, "numpy")
%
%# Make 2D permutation list with K = 0~10 and L = 0~10:
%K_n = np.linspace(0, 10, 50)
%L_n = np.linspace(0, 10, 50)
%
%result = []
%for k in K_n:
%	result_j = []
%	for l in L_n:
%		result_j.append(Ys_func(k, l))
%	result.append(result_j)
%result = np.array(result)
%# Plot 2D heat map:
%#plt.matshow(result)
%\end{pythontexcustomcode}
%%\pyc{}
%\begin{pythontexcustomcode}{py}
%import numpy as np
%import scipy.linalg as la
%import scipy.optimize as opt
%import time
%import quantecon as qe
%
%from collections import namedtuple
%from interpolation.complete_poly import (
%	CompletePolynomial,
%	n_complete,
%	complete_polynomial,
%	complete_polynomial_der,
%	_complete_poly_impl,
%	_complete_poly_impl_vec,
%	_complete_poly_der_impl,
%	_complete_poly_der_impl_vec
%)
%from numba import jit, vectorize
%
%# Create a named tuple type that we can pass into the jitted functions
%# so that we don't have to pass parameteres one by one
%
%Params = namedtuple("Params", ["A", "alpha", "beta", "delta", "gamma", "rho", "sigma"])
%
%@jit(nopython = True)
%def param_unpack(params):
%	"Unpack parameters from the Params type"
%	out = (params.A, params.alpha, params.beta,
%	params.delta, params.gamma, params.rho, params.sigma)
%
%	return out
%
%# Helper function to make sure things are jitted
%@vectorize(nopython = True)
%def u(c, gamma):
%	"CRRA utility function"
%	return -1e10 if c < 1e-10 else (c**(1 - gamma) - 1.0)/(1 - gamma)
%
%@vectorize(nopython = True)
%def du(c, gamma):
%	"Derivative of CRRA utility function"
%	return 1e10 if c < 1e-10 else c**(-gamma)
%
%@vectorize(nopython = True)
%def duinv(u, gamma):
%	"Inverse of the derivative of the CRRA utility function"
%	return u**(-1.0/gamma)
%
%
%@vectorize(nopython = True)
%def f(k, z, A, alpha):
%	"C-D production function"
%	return A*z*k*alpha
%
%@vectorize(nopython = True)
%def df(k, z, A, alpha):
%	"Derivate of C-D production function"
%	return alpha*A*z*k**(alpha - 1.0)
%
%
%@vectorize(nopython = True)
%def expandable_t(k, z, A, alpha, delta):
%	"Budget constraint"
%	return (1-delta)*k + f(k, z, A, alpha)
%
%@vectorize(nopython = True)
%def env_cond_kp(temp, params, degree, v_coeffs, kt, zt):
%	# Unpack parameters
%	A, alpha, beta, delta, gamma, rho, sigma = param_unpack(params)
%
%	# Compute derivative of VF wrt k
%	_complete_poly_der_impl_vec(np.array([kt, zt]), degree, 0, temp)
%
%	c = duinv(np.dot(temp, v_coeffs)/(1.0-delta+df(kt, zt, A, alpha)), gamma)
%	
%	return expandable_t(kt, zt, A, alpha, delta) - c
%
%
%@jit(nopython=True)
%def jit_simulate_ngcm(params, degree, v_coeffs, T, nburn, shocks):
%	"Simulates economy using envelope condition as policy rule"
%	A, alpha, beta, delta, gamma, rho, sigma = param_unpack(params)
%
%	# Allocate space for output
%	ksim = np.empty(T + nburn)
%	zsim = np.empty(T + nburn)
%	ksim[0], zsim[0] = 1.0, 1.0
%
%	# Allocate space for temporary vector to fill with complete polynomials
%	temp = np.empty(n_complete(2, degree))
%
%	# Simulate
%	for t in range(1, T+nburn):
%		# Evaluate policy for today given yesterdays state
%		kp = env_cond_kp(temp, params, degree, v_coeffs, ksim[t - 1], zsim[t - 1])
%
%		# Draw new z and update k using policy from above
%		zsim[t] = zsim[t - 1]**rho*np.exp(sigma*shocks[t])
%		ksim[t] = kp
%
%	return ksim[nburn:], zsim[nburn:]
%
%@jit(nopython=True)
%def jit_ee(params, degree, v_coeffs, nodes, weights, ks, zs):
%	# Unpack parameteres
%	A, alpha, beta, delta, gamma, rho, sigma = param_unpack(params)
%
%	# Allocate space for temporary vector to fill with complete polynomials
%	temp = np.empty(n_complete(2, degree))
%	T = ks.size
%	Qn = weights.size
%
%	# Allocate over all ks and zs
%	for t in range(T):
%		# Current states
%		k, z = ks[t], zs[t]
%
%	# Compute decision for kp and implied c
%	k1 = env_cond_kp(temp, params, degree, v_coeffs, k, z)
%	c = expandable_t(t, k, A, alpha, delta) - k1
%
%	# Compute euler error for period t
%	lhs = du(c, gamma)
%	rhs = 0.0
%	for i in range(Qn):
%		# Get productivity tomorrow
%		z1 = z**rho*np.exp(nodes[i])
%	# Compute decision for kpp and implied c
%	k2 = env_cond_kp(temp, params, degree, v_coeffs, k1, z1)
%	c1 = expandable_t(k1, z1, A, alpha, delta) - k2
%	rhs = rhs + weights[i]*du(c1, gamma)*(1-delta+df(k1, z1, A, alpha))
%
%	ee[t] = np.abs(1.0 - beta*rhs/lhs)
%
%	return ee
%\end{pythontexcustomcode}
%\begin{figure}[ht!]
%	\centering
%	\includegraphics{plot2}
%\end{figure}
\newpage

% aus Mertz, Slough 2013 - A Gentle Introduction to PythonTeX
